{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9bb8ee",
   "metadata": {},
   "source": [
    "Run the Database Connection File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a61723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ./db_connections.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c26f6",
   "metadata": {},
   "source": [
    "Import the Necessary Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb16016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo.errors import PyMongoError\n",
    "from sqlalchemy import create_engine\n",
    "import requests\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "from sqlalchemy import exc\n",
    "from sqlalchemy import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca73a337",
   "metadata": {},
   "source": [
    "Load the Data from the json to the MongoDB Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4efb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform a useful task for managing MongoDB collections. It checks whether the collection is empty, and if not, it drops the collection before loading the JSON data into it. This ensures that the data is added to a clean slate, avoiding any potential conflicts or duplicates.\n",
    "\n",
    "def check_and_load_json_data(json_file, collection):\n",
    "    if collection.count_documents({}) > 0:\n",
    "        collection.drop()\n",
    "        print(\"Existing Collection dropped successfully.\")\n",
    "    else:\n",
    "        print(\"Loading data from JSON file...\")\n",
    "    print(\"Loading data from JSON file...\")\n",
    "\n",
    "    load_json_data(json_file, collection)\n",
    "    print(\"Data loaded successfully from JSON file.\")\n",
    "    \n",
    "# This function is responsible for loading JSON data into a MongoDB collection\n",
    "def load_json_data(json_file, collection):\n",
    "    try:\n",
    "        with open(json_file) as f:\n",
    "            data = json.load(f)\n",
    "            collection.insert_many(data)\n",
    "            print(f\"Loaded {len(data)} records into MongoDB\")\n",
    "    except (FileNotFoundError, ValueError, PyMongoError) as e:\n",
    "        print(f\"Error occurred while loading JSON data into MongoDB: {e}\")\n",
    "        \n",
    "# Connect to MongoDB database using the specified parameters and assigns the connection information to the 'client', 'db', and 'collection' variables.\n",
    "client, db, collection = connect_to_mongodb(mongoConnectionstring, mongoDatabasename, mongoCollectionnameFF)\n",
    "\n",
    "# Check and load data from the 'Food_Service_Inspections.json' file into the MongoDB collection.\n",
    "check_and_load_json_data('Food_Service_Inspections.json', collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267feac",
   "metadata": {},
   "source": [
    "Load the Data from the MongoDB Collection to a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_FoodInspectiondata_to_dataframe(collection):\n",
    "    try:\n",
    "        if collection.count_documents({}) > 0:\n",
    "            # Retrieve data from MongoDB into a DataFrame\n",
    "            FoodInspection_df = pd.DataFrame(list(collection.find()))\n",
    "            print(\"Data loaded into a DataFrame.\")\n",
    "        else:\n",
    "            print(\"No data available in MongoDB collection.\")\n",
    "            FoodInspection_df = None\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while loading data from MongoDB: {e}\")\n",
    "        FoodInspection_df = None\n",
    "    return FoodInspection_df\n",
    "\n",
    "FoodInspection_df = load_FoodInspectiondata_to_dataframe(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FoodInspection_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3400c6d",
   "metadata": {},
   "source": [
    "Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53456ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns that are unnecessary for generating visual representations\n",
    "def remove_columns(df, columns):\n",
    "    return df.drop(columns, axis=1)\n",
    "columns_to_drop = ['_id','STAGE', 'OPNDATE', 'CLSDATE', 'PDIR', 'PSTREET', 'PSTREETTYPE', 'PSTREETSUF', 'PSUITE', 'PCODE', 'ITYPE', 'TIMEIN', 'TIMEOUT', 'TIMESP', 'COMM', 'INSPNO', 'CODE', 'REPEAT', 'CORRECTED']\n",
    "FoodInspection_df = remove_columns(FoodInspection_df, columns_to_drop)\n",
    "\n",
    "# Replace empty cells with None\n",
    "def replace_empty_strings_with_none(dataframe):\n",
    "    return dataframe.replace('', None, inplace=True)\n",
    "replace_empty_strings_with_none(FoodInspection_df)\n",
    "\n",
    "# Remove missing values\n",
    "def drop_rows_with_missing_values(dataframe):\n",
    "    return dataframe.dropna(inplace=False)\n",
    "FoodInspection_df = drop_rows_with_missing_values(FoodInspection_df)\n",
    "\n",
    "# Remove duplicates \n",
    "def drop_duplicates(dataframe):     # drop duplicate rows\n",
    "    dataframe = dataframe.drop_duplicates()\n",
    "    dataframe = dataframe.loc[:,~dataframe.columns.duplicated()]     # drop duplicate columns    \n",
    "    return dataframe\n",
    "print('Number of rows before removing duplicates:', FoodInspection_df.shape[0])\n",
    "print('Number of columns before removing duplicates:', FoodInspection_df.shape[1])\n",
    "FoodInspection_df = drop_duplicates(FoodInspection_df) # remove duplicates using the drop_duplicates() function\n",
    "print('Number of rows after removing duplicates:', FoodInspection_df.shape[0])\n",
    "print('Number of columns after removing duplicates:', FoodInspection_df.shape[1])\n",
    "\n",
    "# Count the number of duplicates in the dataset\n",
    "def count_duplicate_rows(dataframe):\n",
    "    return dataframe.duplicated().sum()\n",
    "num_duplicates = count_duplicate_rows(FoodInspection_df)\n",
    "print(\"Number of duplicates in the dataset: \", num_duplicates)\n",
    "\n",
    "# Count the number of missing values in each column of the DataFrame\n",
    "def count_missing_values(dataframe):\n",
    "    num_missing = dataframe.isnull().sum()\n",
    "    return num_missing.sum()\n",
    "num_missing = count_missing_values(FoodInspection_df)\n",
    "print(f\"Total number of missing values: {num_missing}\")\n",
    "\n",
    "# Count the num of invalid values in the dataset\n",
    "def count_invalid_values(dataframe):\n",
    "    num_invalid_values = dataframe.isnull().sum().sum()\n",
    "    return num_invalid_values\n",
    "num_invalid_values = count_invalid_values(FoodInspection_df)\n",
    "print(\"There are {} invalid values in the dataset.\".format(num_invalid_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names for easy understanding of data\n",
    "def rename_columns(df):\n",
    "    column_map = {\n",
    "        'UNID': 'identification',\n",
    "        'NAME': 'name',\n",
    "        'STATUS': 'status',\n",
    "        'TYPE': 'type',\n",
    "        'RANKING': 'ranking',\n",
    "        'PBUILD': 'address',\n",
    "        'PCITY': 'city',\n",
    "        'PSTATE': 'state',\n",
    "        'EDATE': 'date',\n",
    "        'CriticalTier': 'critical'\n",
    "    } \n",
    "    df.rename(columns=column_map, inplace=True) \n",
    "    return df\n",
    "rename_columns(FoodInspection_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf415e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FoodInspection_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FoodInspection_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44b10e5",
   "metadata": {},
   "source": [
    "Write the cleaned DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c96bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FoodInspection_df.to_csv('cleaned_food_inspection_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce852f",
   "metadata": {},
   "source": [
    "Loading the saved Csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2476b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "FoodInspectionCleaned = pd.read_csv(\"cleaned_food_inspection_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0293216c",
   "metadata": {},
   "source": [
    "Table Creation and Data Loading into PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56cc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that generates a table within a PostgreSQL database to store data related to food inspections.\n",
    "\n",
    "def create_foodInspection_table(conn, table_name):\n",
    "    try:\n",
    "        cur = conn.cursor() # Generate a cursor instance that can be used to execute SQL queries.\n",
    "        # SQL query used for constructing a table that specifies the column names and their respective data types.\n",
    "        cur.execute(f'''\n",
    "            CREATE TABLE IF NOT EXISTS {table_name} (identification VARCHAR(255),\n",
    "                name VARCHAR(255),\n",
    "                status VARCHAR(255),\n",
    "                type VARCHAR(255),\n",
    "                ranking VARCHAR(255),\n",
    "                address VARCHAR(255),\n",
    "                city VARCHAR(255),\n",
    "                state VARCHAR(255),\n",
    "                date DATE,\n",
    "                critical VARCHAR(255)\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit() # save changes made to the database by a transaction.\n",
    "        print(\"Table created successfully!\")\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Error creating table:\", e)\n",
    "        conn.rollback() #  used to undo the changes made to the database during a transaction in case of an error.\n",
    "    finally:\n",
    "        cur.close() #release the database cursor.\n",
    "        \n",
    "table_name = postgresFoodinspectiontablename\n",
    "create_foodInspection_table(conn, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d22c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Function designed to transfer data from a DataFrame to a table in PostgreSQL\n",
    "\n",
    "def loadFoodinspection_data_to_postgresql(conn, df, table_name):\n",
    "    try:\n",
    "        engine = establish_postgres_connection(postgresUsername, postgresPassword, postgresHost, postgresPort, postgresDbname)\n",
    "        inspector = inspect(engine)\n",
    "        # \"Verify whether the table has any existing data, and if it does, remove all rows from it.\"\n",
    "        if table_name in inspector.get_table_names():\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(f\"DELETE FROM {table_name}\")\n",
    "                conn.commit()  # Commit the DELETE statement\n",
    "                #print(f\"All rows deleted from table '{table_name}'.\")\n",
    "        FoodInspectionCleaned.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "        engine.dispose() # Dispose the engine after data is loaded.\n",
    "        print(\"Data loaded to PostgreSQL successfully!\")\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        print(\"Error loading data to PostgreSQL:\", e)\n",
    "        \n",
    "loadFoodinspection_data_to_postgresql(conn, FoodInspectionCleaned, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb14d80",
   "metadata": {},
   "source": [
    "Extract the Pre-processed and Structured Data that was loaded into Postgres into a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0802b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that retrieves data from a PostgreSQL table and transfers it into a DataFrame.\n",
    "\n",
    "def extract_foodinspection_data_from_postgresql(engine, table_name):\n",
    "    try:\n",
    "        \n",
    "        # Define the query to extract data\n",
    "        query = f'SELECT * FROM {table_name}'\n",
    "        df = pd.read_sql(query, engine)\n",
    "        print(\"Data loaded from PostgreSQL to DataFrame successfully!\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"Error loading data from PostgreSQL to DataFrame:\", e)\n",
    "\n",
    "engine = establish_postgres_connection(postgresUsername, postgresPassword, postgresHost, postgresPort, postgresDbname)\n",
    "FoodInspection_df = extract_foodinspection_data_from_postgresql(engine, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeadb223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn.close() #Close the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e84b47",
   "metadata": {},
   "source": [
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67758f7a",
   "metadata": {},
   "source": [
    "1) Bar chart showing the number of inspections conducted for each establishment type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f216e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "insp_by_type = FoodInspection_df.groupby('type')['identification'].count().reset_index()\n",
    "insp_by_type = insp_by_type.rename(columns={'identification': 'Count'})\n",
    "plt.bar(insp_by_type['type'], insp_by_type['Count'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Establishment Type')\n",
    "plt.ylabel('Number of Inspections')\n",
    "plt.title('Number of Inspections by Establishment Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f928c67",
   "metadata": {},
   "source": [
    "2) Horizontal bar chart showing the percentage of establishments with active, inactive, or other license statuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa1e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_count = FoodInspection_df['status'].value_counts().reset_index()\n",
    "status_count = status_count.rename(columns={'index': 'Status', 'status': 'Count'})\n",
    "plt.barh(status_count['Status'], status_count['Count'])\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Status')\n",
    "plt.title('Inspection Status Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c77d96",
   "metadata": {},
   "source": [
    "3) Violation distribution by type and ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ranking_counts = FoodInspection_df.groupby(['type', 'ranking']).size().unstack(fill_value=0)\n",
    "type_ranking_counts.plot(kind='bar', stacked=True)\n",
    "plt.xlabel('Type of Violation')\n",
    "plt.ylabel('Number of Violations')\n",
    "plt.title('Violation Distribution by Type and Ranking')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2212df84",
   "metadata": {},
   "source": [
    "4) Most common violations by type and ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_counts = FoodInspection_df.groupby(['type', 'ranking']).size().reset_index(name='count')\n",
    "most_common = violation_counts.sort_values('count', ascending=False).groupby('type').head(1)\n",
    "most_common.plot(kind='bar', x='type', y='count', color='blue')\n",
    "plt.title('Most Common Violations by Type and Ranking')\n",
    "plt.xlabel('Violation Type')\n",
    "plt.ylabel('Violation Count')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
